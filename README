This project looks into developing an AutoEncoder model and utilizing the CIFAR 10 dataset.

NB: I have removed the frog images from the dataset because I actually have a slight phobia of them. :'(

## Overview ##
The entire code is written within Jupyter Notebook.
The code looks into developing an autoencoder model. Three models has been developed (more discussion in the process section).

The models are:
    - DAE  - supervised model using MSE loss function
    - DAE2 - supervised model using BinaryCrossEntropy loss function
    - DAE3 - unsupervised model using MSE loss function

The denoised output are saved in cifar_output.npz. Each output from the models are saved as:
"denoised1", "denoised2", "denoised3"
The denoised output can be located here: https://drive.google.com/drive/folders/1EJhDvToM9d5-3CsKV9G2AhQdopItbZzH?usp=sharing

The predicted output of the models are evaluated using Image Quality Metrics
- MSE (Mean Squared Error)
- PSNR (Peak Signal-to-Noise Ratio)
- SSIM (Structured Similary Index)

The models are also evaluated on Non-CIFAR 10 images called Flowers by the TensorFlow team.

## Process ##
This is the very first model(s) I have ever created and it was a big learning curve but it was very rewarding.

Here are a list of websites that I used to learn about AutoEncoders:
- https://www.tensorflow.org/tutorials/generative/autoencoder
- https://www.deeplearningbook.org/ (Deep Learning Book: Chapter 14)

Questions during the project:
Q: How to create a model?
A: There a multiple ways to create a model. They can be created either via "Functional API", subclassing the Model class or with the sequential class. I used the subclassing the Model class options as I found it easier to read. [1]

Q: How to structure the hidden layers?
A: First I needed to understand what are the layers for a CNN. These are Convolution Layer, Pooling Layer and Dense Layers. I have figured out that there is no one to one answer. It really depends on the image dataset and experimentation of different components. I have not yet fully grasped all of the layers but I have taken a look at sample autoencoders and how they structured their layers. I have found out that the encoder and decoder are almost opposite from one another. So I have structured my layers by filtering an incrementing amount of CONV layers with BN and ReLU in between. Therefore the encoder is as follows:
CONV(16) => BN => RELU => CONV(32) => BN => RELU ==> CONV(64) => BN => RELU ==> CONV(128) => BN => RELU
The decoder is just the opposite. This can be further improved. And I wish to improve it more as I learn more about CNNs.s

Q: How to load and save a model?
A: You can use model.save() and tf.keras.models.load_model().[2] HOWEVER, this depends on how you developed the model. I didn't know that I chose the most readable model to make using the sublclass of the Model class but it being the hardest to save because of the Model I created is a custom model.
Since the class I made Denoise is within the same Jupyter Notebook, then the import is not a problem.

Q: Which loss function to use?
A: The most common loss function is MSE Loss and L1 Loss for autoencoders. [3] I also chose to use BinaryCrossEntropy which is meant to be good for classification as I wanted to see what if it even makes a difference. Answer: Very little.

Q: How to run the model?
A: Once the training is done, you can use model.predict(input_image) to create a denoised output.

Q: Which Image Quality Metric to use?
A: Image Quality Metric considered are: MSE, PSNR, SSIM, VIF.

Q: What are some other available image datasets?
A: I have found image datasets here in [4] and I was figuring out how to easily load them. Similar to how the CIFAR10 was easily loaded. So I checked for other available datasets in tensorflow [5] but none are coloured except for CIFAR10 and CIFAR100. I then found the TensorFlow Flower Dataset when trying to search for ways to load the ImageNet and used that instead [6].

Q: How to use the model for other image datasets?
A: You can use any dataset however you must make sure to preprocess the images to fit the input size required by your model. This is of size (32, 32, 3). The noise are added using the available add_gaussian_noise() function.


Future work:
- Identify how the models can be improved
- Fully understand how layers work in CNNs (for further reading: [7])

Links:
[1] https://www.tensorflow.org/api_docs/python/tf/keras/Model
[2] https://www.tensorflow.org/guide/keras/serialization_and_saving
[3] https://medium.com/@bhipanshudhupar/loss-functions-in-simple-autoencoders-mse-vs-l1-loss-4e838ae425b9#:~:text=Reconstruction%20Loss%3A%20When%20training%20an,in%20guiding%20the%20training%20process.
[4] https://paperswithcode.com/datasets?mod=images
[5] https://www.tensorflow.org/api_docs/python/tf/keras/datasets
[6] https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub
[7] https://poloclub.github.io/cnn-explainer/

Personal Information
Name: Kenneth Cynric Dasalla
Contact: 07852903622
Email: dasallakc@gmail.com